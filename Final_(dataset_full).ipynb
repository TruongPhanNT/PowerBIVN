{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final (dataset full).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "si_JTquP-lUH",
        "DcL7_ewi-lUX",
        "08ld4Z6m-lUa",
        "85S46EUz-lUe",
        "-4BEfXr4-lUi",
        "CpWsNgAm-lVF",
        "suXunJdtFNuA",
        "bbB5auqqJHG_",
        "exGu8XpBI7H2",
        "JI-RNOjcTfGL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TruongPhanNT/PowerBIVN/blob/master/Final_(dataset_full).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py0GceaO-lUF"
      },
      "source": [
        "# Forecast Time Series by Using Common Machine Learning Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWi6HzuEXwYc"
      },
      "source": [
        "## Nội dung chính\n",
        "\n",
        "\n",
        "1.   Dự báo trên tập dataset 1 lấy từ Yahoo Finance: Mã stock là Rough Rice Nov 20 (RR=F)\n",
        "2.   Fill dữ liệu bằng pchip/ cubic\n",
        "3.   Xây dựng các mô hình dự báo Bayes Regressor, LSTM, và ARIMA\n",
        "4.   Split tập training, test set lần lượt theo tỉ lệ 70/30, 80/20 và 90/10\n",
        "5.   Thử nghiệm và so sánh các mô hình để chọn ra mô  hình tối ưu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si_JTquP-lUH"
      },
      "source": [
        "# 1. Install neccessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msRYl75--lUI",
        "outputId": "5bfbaacc-0b5d-4c43-d15f-f99922b24906"
      },
      "source": [
        "!pip install stockai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stockai in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: ciso8601 in /usr/local/lib/python3.7/dist-packages (from stockai) (2.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stockai) (2.23.0)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.7/dist-packages (from stockai) (0.5.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stockai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stockai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stockai) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stockai) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGnvbrW2-lUN",
        "outputId": "256573ba-34f9-482d-8d22-b5fe7beb0846"
      },
      "source": [
        "!pip install pytictoc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytictoc in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcL7_ewi-lUX"
      },
      "source": [
        "# 2. Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9AEi4bE-lUX"
      },
      "source": [
        "from stockai import Stock\n",
        "import numpy as np\n",
        "from numpy import concatenate\n",
        "from math import sqrt\n",
        " \n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import pandas as pd \n",
        " \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        " \n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        " \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        " \n",
        "from matplotlib import pyplot\n",
        " \n",
        "import scipy\n",
        " \n",
        "import dateutil\n",
        "import datetime as dt\n",
        "import time\n",
        "from pytictoc import TicToc\n",
        "t = TicToc() #create instance of class\n",
        " \n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjvPedCcS4ac"
      },
      "source": [
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.max_rows', 50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6Z2C_Pm-lUa"
      },
      "source": [
        "# 3. Load & convert dataset\n",
        " \n",
        "*   List item\n",
        "*   List item"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08ld4Z6m-lUa"
      },
      "source": [
        "## 3.1 Load Market Data from Yahoo Finance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8rtakLe-lUb",
        "outputId": "60db3671-a290-47dd-8cc4-6e708ccdb3d1"
      },
      "source": [
        "# RICE ROUGH\n",
        "td = Stock('ZR=F')\n",
        "#td.get_historical_prices('2020-01-01', '2021-03-11')\n",
        " \n",
        " \n",
        "prices_list = td.get_historical_prices('2005-01-01', '2021-01-01')\n",
        " \n",
        "df = pd.DataFrame.from_dict(prices_list)\n",
        "print(df.head(10))\n",
        " \n",
        "print('Rows:', df.shape[0])\n",
        "print('Rows missing value:',df.isnull().any(axis = 1).sum())\n",
        "pc = 100* df.isnull().any(axis = 1).sum()/df.shape[0]\n",
        "print('Pecentage of missing value rows (%):', pc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         date  close   high   open    low  volume  adjclose\n",
            "0  1104728400  686.0  726.0  726.0  725.5     3.0     686.0\n",
            "1  1104814800  690.0  690.0  690.0  690.0     3.0     690.0\n",
            "2  1104901200  694.0  694.0  694.0  694.0     3.0     694.0\n",
            "3  1104987600  706.0  706.0  706.0  706.0     3.0     706.0\n",
            "4  1105074000  711.0  711.0  711.0  711.0     3.0     711.0\n",
            "5  1105333200  706.0  706.0  706.0  706.0     3.0     706.0\n",
            "6  1105419600  693.0  693.0  693.0  693.0     3.0     693.0\n",
            "7  1105506000  689.0  689.0  689.0  689.0     3.0     689.0\n",
            "8  1105592400  696.0  696.0  696.0  696.0     3.0     696.0\n",
            "9  1105678800  695.0  695.0  695.0  695.0     3.0     695.0\n",
            "Rows: 4049\n",
            "Rows missing value: 77\n",
            "Pecentage of missing value rows (%): 1.9017041244751791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llzSLeKkgo2s"
      },
      "source": [
        "**Vì phần trăm dữ liệu missing >5% nên không dùng phương pháp drop được. Tức là df_fill==dropna không dùng**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85S46EUz-lUe"
      },
      "source": [
        "## 3.2 Define function to fill missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F00nHsQt-lUf"
      },
      "source": [
        "def fill_missing_values(df, fill_method='ffill', fill_order=5):\n",
        "    if fill_method=='0':\n",
        "        df_fill= df.fillna(0)  \n",
        "    if fill_method=='mean':\n",
        "        df_fill= df.fillna(df.mean())\n",
        "    if fill_method=='dropna':\n",
        "        df_fill = df.dropna()              \n",
        "    if fill_method in ('ffill','bfill'):\n",
        "        df_fill= df.fillna(method=fill_method)\n",
        "    if fill_method in ('linear','quadratic','cubic','nearest'):\n",
        "        df_fill=df.interpolate(method=fill_method)\n",
        "    if fill_method in ('polynomial','piecewise_polynomial','pchip','slinear'):\n",
        "        df_fill=df.interpolate(method=fill_method, order=fill_order)\n",
        "    return df_fill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxIA3qs3-lUh"
      },
      "source": [
        "# 4. Split dataset into training set, test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4BEfXr4-lUi"
      },
      "source": [
        "## 4.1 Feature Engineering for Time Series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJbrtSFj-lUi"
      },
      "source": [
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "    n_vars = 1 if type(data) is list else data.shape[1]\n",
        "    df = DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(n_in, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, n_out):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "    # put it all together\n",
        "    agg = concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvCVolMu-lUk"
      },
      "source": [
        "#split dataset into training, test set --> Dùng tỉ lệ 90% train và 10% test\n",
        "def split_train_test (dataset, traing_ratio=.9, sliding_size=4):\n",
        "    values = dataset.values\n",
        "    # ensure all data is float\n",
        "    values = values.astype('float32')\n",
        "    # normalise features\n",
        "    scaler = MinMaxScaler(feature_range=(0,1))\n",
        "    scaled = scaler.fit_transform(values)\n",
        "    # frame as supervised learning\n",
        "    n_mins = sliding_size\n",
        " \n",
        "    reframed = series_to_supervised(scaled, n_mins, 1)\n",
        "   \n",
        "    # split into train and test sets\n",
        "    count_row_reframed = reframed.shape[0]  # gives number of row count\n",
        " \n",
        "    values = reframed.values\n",
        " \n",
        "    n_train_mins = int(4 * 1 * (count_row_reframed*traing_ratio/(4*1))) \n",
        " \n",
        " \n",
        "    train = values[:n_train_mins, :]\n",
        "    test = values[n_train_mins:, :]\n",
        "    # split into input and outputs\n",
        "    n_obs = n_mins * 1\n",
        "    train_X, train_y = train[:, :n_obs], train[:, -1]\n",
        "    test_X,  test_y =test[:, :n_obs], test[:,-1]\n",
        "    #print(train_y,test_y)\n",
        "    return train_X, train_y, test_X, test_y, scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GurOmZX-lUn"
      },
      "source": [
        "#drop non predict columns\n",
        "def drop_non_predict_columns (df):\n",
        "    ts_df = pd.DataFrame()\n",
        " \n",
        "    # assign column\n",
        "    ts_df['date'] = df.date.astype(str).replace('-', '')\n",
        "    ts_df['val'] = df['adjclose']\n",
        " \n",
        "    #set date as index column\n",
        "    ts_df.set_index('date',inplace=True)\n",
        "    #sort order by date\n",
        "    ts_df = ts_df.sort_index()\n",
        "    return ts_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdcKYC0s-lUp"
      },
      "source": [
        "# 5. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-5WTCHb-lUq"
      },
      "source": [
        "## 5.1 Bayes Ridge \n",
        "\n",
        "(đây là một loại thuật toán thuộc ANN: cần đọc thêm bài báo: https://onlinelibrary.wiley.com/doi/abs/10.1111/jbg.12468) --> Trong báo cáo lướt qua các loại Bayes: traditional, Lasso, .... nhưng trong bài báo. Và nêu ra ưu điểm, khuyết điểm của các loại phương pháp này. Điều này rất có ích để khi ra có kết quả đánh giá hình vẽ, hay số liệu mà giải thích được. Đề nghị bổ sung vào báo cáo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt_p4nMT-lUq"
      },
      "source": [
        "def Model_BayesianRidge (train_X,train_y,test_X, test_y, scaler, sliding_size=4):\n",
        "    t.tic() #Start timer\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    # design svm model\n",
        "    model = BayesianRidge()\n",
        " \n",
        "    # fit model\n",
        "    model.fit(train_X,train_y)\n",
        " \n",
        "    t.toc() #End timer\n",
        "    \n",
        "    running_time =time.perf_counter()-start_time\n",
        "    # make a prediction\n",
        "    predict_y = model.predict(test_X)\n",
        "    yhat = predict_y.reshape(predict_y.shape[0],1)\n",
        "    test_X = test_X.reshape((test_X.shape[0],sliding_size*1))\n",
        " \n",
        "    # invert scaling for forecast\n",
        "    inv_yhat = concatenate((test_X[:, -1:-1], yhat), axis=1)\n",
        "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "    inv_yhat = inv_yhat[:,-1]\n",
        " \n",
        " \n",
        "    # invert scaling for actual\n",
        "    test_y = test_y.reshape((len(test_y), 1))\n",
        "    inv_y = concatenate((test_X[:, -1:-1], test_y), axis=1)\n",
        "    inv_y = scaler.inverse_transform(inv_y)\n",
        "    inv_y = inv_y[:,-1]\n",
        " \n",
        "    # calculate RMSE\n",
        "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "    # calculate MAPE\n",
        "    mape = np.mean(np.fabs((inv_y - inv_yhat) / inv_y)) * 100\n",
        "    \n",
        "    return model, rmse, mape, inv_yhat, inv_y, running_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpWsNgAm-lVF"
      },
      "source": [
        "## 5.2 LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crq_AX_1-lVF"
      },
      "source": [
        "def Model_SingleLSTM (train_X,train_y,test_X, test_y, scaler, sliding_size=4):\n",
        "    t.tic() #Start timer\n",
        "    start_time = time.perf_counter()\n",
        "    \n",
        "    # reshape input to be [samples, time steps, features]\n",
        "    trainX = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
        "    testX = np.reshape(test_X, (test_X.shape[0], test_X.shape[1], 1))\n",
        "    \n",
        "    # create and fit the LSTM network\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(16, input_shape=(sliding_size, 1)))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    model.fit(trainX, train_y, epochs=100, batch_size=20, verbose=2)\n",
        " \n",
        "    t.toc() #End timer\n",
        "    \n",
        "    running_time =time.perf_counter()-start_time\n",
        "    # make a prediction\n",
        "    predict_y = model.predict(testX) \n",
        "    yhat = predict_y.reshape(predict_y.shape[0],1)\n",
        "    testX = testX.reshape((testX.shape[0],sliding_size*1))\n",
        " \n",
        "    # invert scaling for forecast\n",
        "    inv_yhat = concatenate((testX[:, -1:-1], yhat), axis=1)\n",
        "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "    inv_yhat = inv_yhat[:,-1]\n",
        " \n",
        "    # invert scaling for actual\n",
        "    test_y = test_y.reshape((len(test_y), 1))\n",
        "    inv_y = concatenate((testX[:, -1:-1], test_y), axis=1)\n",
        "    inv_y = scaler.inverse_transform(inv_y)\n",
        "    inv_y = inv_y[:,-1]\n",
        " \n",
        "    # calculate RMSE\n",
        "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "    # calculate MAPE\n",
        "    mape = np.mean(np.fabs((inv_y - inv_yhat) / inv_y)) * 100\n",
        "    \n",
        "    return model, rmse, mape, inv_yhat, inv_y, running_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suXunJdtFNuA"
      },
      "source": [
        "## 5.3 ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thDzj6aeRWx9"
      },
      "source": [
        "def Model_ARIMA (train_data, test_data):\n",
        "  \n",
        "  training_data = train_data['val'].values\n",
        "  test_data = test_data['val'].values\n",
        "  history = [x for x in training_data]\n",
        "  model_predictions = []\n",
        "  N_test_observations = len(test_data)\n",
        " \n",
        "  t.tic() #Start timer\n",
        "  start_time = time.perf_counter()\n",
        " \n",
        "  print (range(N_test_observations))\n",
        "  for time_point in range(N_test_observations):\n",
        "      model = ARIMA(history, order=(4,1,0))\n",
        "      model_fit = model.fit(disp=0)\n",
        "      output = model_fit.forecast()\n",
        "      yhat = output[0]\n",
        "      model_predictions.append(yhat)\n",
        "      true_test_value = test_data[time_point]\n",
        "      history.append(true_test_value)\n",
        "      print(time_point)\n",
        "  print(model_fit.summary())\n",
        " \n",
        "  t.toc() #End timer\n",
        "  running_time =time.perf_counter()-start_time \n",
        "  # RMSE\n",
        "  rmse = sqrt(mean_squared_error(test_data, model_predictions))\n",
        "  # MAPE\n",
        "  mape = np.mean(np.fabs((test_data - model_predictions) / test_data)) * 100\n",
        " \n",
        "  #pyplot.plot(test_data, linestyle='solid', color='blue', label='Actual')\n",
        "  #pyplot.plot(model_predictions, linestyle='--', color='red', label='Prediction - ARIMA')\n",
        " \n",
        "  return model, rmse, mape, model_predictions, test_data, running_time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLoyA_M9FXNx"
      },
      "source": [
        "# 6 Run & Test model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WH7IMUkrPRs"
      },
      "source": [
        "### 6.1 Use pchip method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbB5auqqJHG_"
      },
      "source": [
        "### 6.1.1 Split training set, test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raLEv7R0H-Ei"
      },
      "source": [
        "#fill missing values\n",
        "fill_df = fill_missing_values(df, fill_method='pchip',fill_order=5)\n",
        "#drop non\n",
        "dataset = drop_non_predict_columns (fill_df)\n",
        "#split dataset into training and test set\n",
        "train_X7, train_y7, test_X7, test_y7, scaler7 = split_train_test (dataset, traing_ratio=.7, sliding_size=4)\n",
        "train_X8, train_y8, test_X8, test_y8, scaler8 = split_train_test (dataset, traing_ratio=.8, sliding_size=4)\n",
        "train_X9, train_y9, test_X9, test_y9, scaler9 = split_train_test (dataset, traing_ratio=.9, sliding_size=4)\n",
        " \n",
        "#training for arima\n",
        "a_train_data7, a_test_data7 = dataset[0:int(len(dataset)*0.7)], dataset[int(len(dataset)*0.7):]\n",
        "a_train_data8, a_test_data8 = dataset[0:int(len(dataset)*0.8)], dataset[int(len(dataset)*0.8):]\n",
        "a_train_data9, a_test_data9 = dataset[0:int(len(dataset)*0.9)], dataset[int(len(dataset)*0.9):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exGu8XpBI7H2"
      },
      "source": [
        "### 6.1.2 Run models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d6TJeAoFB8K",
        "outputId": "ca183f4b-14f4-4b77-f2f9-d83d841e6bb9"
      },
      "source": [
        "#BAYES RIDGE\n",
        "b7_model, b7_rmse, b7_mape, b7_inv_yhat, b7_inv_y, running_time7 = Model_BayesianRidge (train_X7,train_y7,test_X7, test_y7, scaler7)\n",
        "b8_model, b8_rmse, b8_mape, b8_inv_yhat, b8_inv_y, running_time8 = Model_BayesianRidge (train_X8,train_y8,test_X8, test_y8, scaler8)\n",
        "b9_model, b9_rmse, b9_mape, b9_inv_yhat, b9_inv_y, running_time9 = Model_BayesianRidge (train_X9,train_y9,test_X9, test_y9, scaler9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed time is 0.035021 seconds.\n",
            "Elapsed time is 0.003250 seconds.\n",
            "Elapsed time is 0.001919 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW7z--P-Esdb",
        "outputId": "49afc20d-9ce4-449a-cfe4-4370c980109c"
      },
      "source": [
        "#tLSTM\n",
        "lstm7_model, lstm7_rmse, lstm7_mape, lstm7_inv_yhat, lstm7_inv_y, lstm_running_time7 = Model_SingleLSTM (train_X7,train_y7,test_X7, test_y7, scaler7)\n",
        "lstm8_model, lstm8_rmse, lstm8_mape, lstm8_inv_yhat, lstm8_inv_y, lstm_running_time8 = Model_SingleLSTM (train_X8,train_y8,test_X8, test_y8, scaler8)\n",
        "lstm9_model, lstm9_rmse, lstm9_mape, lstm9_inv_yhat, lstm9_inv_y, lstm_running_time9 = Model_SingleLSTM (train_X9,train_y9,test_X9, test_y9, scaler9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "142/142 - 2s - loss: 0.0255\n",
            "Epoch 2/100\n",
            "142/142 - 0s - loss: 0.0014\n",
            "Epoch 3/100\n",
            "142/142 - 0s - loss: 5.2710e-04\n",
            "Epoch 4/100\n",
            "142/142 - 0s - loss: 4.8139e-04\n",
            "Epoch 5/100\n",
            "142/142 - 0s - loss: 4.3577e-04\n",
            "Epoch 6/100\n",
            "142/142 - 0s - loss: 4.1205e-04\n",
            "Epoch 7/100\n",
            "142/142 - 0s - loss: 3.7872e-04\n",
            "Epoch 8/100\n",
            "142/142 - 0s - loss: 3.6295e-04\n",
            "Epoch 9/100\n",
            "142/142 - 0s - loss: 3.6304e-04\n",
            "Epoch 10/100\n",
            "142/142 - 0s - loss: 3.5274e-04\n",
            "Epoch 11/100\n",
            "142/142 - 0s - loss: 3.4210e-04\n",
            "Epoch 12/100\n",
            "142/142 - 0s - loss: 3.3531e-04\n",
            "Epoch 13/100\n",
            "142/142 - 0s - loss: 3.3662e-04\n",
            "Epoch 14/100\n",
            "142/142 - 0s - loss: 3.2742e-04\n",
            "Epoch 15/100\n",
            "142/142 - 0s - loss: 3.2528e-04\n",
            "Epoch 16/100\n",
            "142/142 - 0s - loss: 3.2877e-04\n",
            "Epoch 17/100\n",
            "142/142 - 0s - loss: 3.1869e-04\n",
            "Epoch 18/100\n",
            "142/142 - 0s - loss: 3.1627e-04\n",
            "Epoch 19/100\n",
            "142/142 - 0s - loss: 3.1976e-04\n",
            "Epoch 20/100\n",
            "142/142 - 0s - loss: 3.1466e-04\n",
            "Epoch 21/100\n",
            "142/142 - 0s - loss: 3.0686e-04\n",
            "Epoch 22/100\n",
            "142/142 - 0s - loss: 3.0549e-04\n",
            "Epoch 23/100\n",
            "142/142 - 0s - loss: 3.0249e-04\n",
            "Epoch 24/100\n",
            "142/142 - 0s - loss: 3.0209e-04\n",
            "Epoch 25/100\n",
            "142/142 - 0s - loss: 2.9944e-04\n",
            "Epoch 26/100\n",
            "142/142 - 0s - loss: 2.9430e-04\n",
            "Epoch 27/100\n",
            "142/142 - 0s - loss: 2.8923e-04\n",
            "Epoch 28/100\n",
            "142/142 - 0s - loss: 2.9049e-04\n",
            "Epoch 29/100\n",
            "142/142 - 0s - loss: 2.8398e-04\n",
            "Epoch 30/100\n",
            "142/142 - 0s - loss: 2.8350e-04\n",
            "Epoch 31/100\n",
            "142/142 - 0s - loss: 2.8918e-04\n",
            "Epoch 32/100\n",
            "142/142 - 0s - loss: 2.8959e-04\n",
            "Epoch 33/100\n",
            "142/142 - 0s - loss: 2.7674e-04\n",
            "Epoch 34/100\n",
            "142/142 - 0s - loss: 2.6267e-04\n",
            "Epoch 35/100\n",
            "142/142 - 0s - loss: 2.6401e-04\n",
            "Epoch 36/100\n",
            "142/142 - 0s - loss: 2.6446e-04\n",
            "Epoch 37/100\n",
            "142/142 - 0s - loss: 2.5581e-04\n",
            "Epoch 38/100\n",
            "142/142 - 0s - loss: 2.4777e-04\n",
            "Epoch 39/100\n",
            "142/142 - 0s - loss: 2.4366e-04\n",
            "Epoch 40/100\n",
            "142/142 - 0s - loss: 2.4066e-04\n",
            "Epoch 41/100\n",
            "142/142 - 0s - loss: 2.4166e-04\n",
            "Epoch 42/100\n",
            "142/142 - 0s - loss: 2.3514e-04\n",
            "Epoch 43/100\n",
            "142/142 - 0s - loss: 2.3121e-04\n",
            "Epoch 44/100\n",
            "142/142 - 0s - loss: 2.2859e-04\n",
            "Epoch 45/100\n",
            "142/142 - 0s - loss: 2.3184e-04\n",
            "Epoch 46/100\n",
            "142/142 - 0s - loss: 2.2051e-04\n",
            "Epoch 47/100\n",
            "142/142 - 0s - loss: 2.1101e-04\n",
            "Epoch 48/100\n",
            "142/142 - 0s - loss: 2.0769e-04\n",
            "Epoch 49/100\n",
            "142/142 - 0s - loss: 2.1374e-04\n",
            "Epoch 50/100\n",
            "142/142 - 0s - loss: 2.0409e-04\n",
            "Epoch 51/100\n",
            "142/142 - 0s - loss: 1.9958e-04\n",
            "Epoch 52/100\n",
            "142/142 - 0s - loss: 1.9595e-04\n",
            "Epoch 53/100\n",
            "142/142 - 0s - loss: 1.9999e-04\n",
            "Epoch 54/100\n",
            "142/142 - 0s - loss: 1.8439e-04\n",
            "Epoch 55/100\n",
            "142/142 - 0s - loss: 1.8842e-04\n",
            "Epoch 56/100\n",
            "142/142 - 0s - loss: 1.8570e-04\n",
            "Epoch 57/100\n",
            "142/142 - 0s - loss: 1.7832e-04\n",
            "Epoch 58/100\n",
            "142/142 - 0s - loss: 1.8121e-04\n",
            "Epoch 59/100\n",
            "142/142 - 0s - loss: 1.6909e-04\n",
            "Epoch 60/100\n",
            "142/142 - 0s - loss: 1.6604e-04\n",
            "Epoch 61/100\n",
            "142/142 - 0s - loss: 1.7367e-04\n",
            "Epoch 62/100\n",
            "142/142 - 0s - loss: 1.7288e-04\n",
            "Epoch 63/100\n",
            "142/142 - 0s - loss: 1.6990e-04\n",
            "Epoch 64/100\n",
            "142/142 - 0s - loss: 1.6239e-04\n",
            "Epoch 65/100\n",
            "142/142 - 0s - loss: 1.6396e-04\n",
            "Epoch 66/100\n",
            "142/142 - 0s - loss: 1.6156e-04\n",
            "Epoch 67/100\n",
            "142/142 - 0s - loss: 1.6929e-04\n",
            "Epoch 68/100\n",
            "142/142 - 0s - loss: 1.6712e-04\n",
            "Epoch 69/100\n",
            "142/142 - 0s - loss: 1.5441e-04\n",
            "Epoch 70/100\n",
            "142/142 - 0s - loss: 1.5994e-04\n",
            "Epoch 71/100\n",
            "142/142 - 0s - loss: 1.6172e-04\n",
            "Epoch 72/100\n",
            "142/142 - 0s - loss: 1.5960e-04\n",
            "Epoch 73/100\n",
            "142/142 - 0s - loss: 1.6186e-04\n",
            "Epoch 74/100\n",
            "142/142 - 0s - loss: 1.5491e-04\n",
            "Epoch 75/100\n",
            "142/142 - 0s - loss: 1.5351e-04\n",
            "Epoch 76/100\n",
            "142/142 - 0s - loss: 1.5958e-04\n",
            "Epoch 77/100\n",
            "142/142 - 0s - loss: 1.6060e-04\n",
            "Epoch 78/100\n",
            "142/142 - 0s - loss: 1.5343e-04\n",
            "Epoch 79/100\n",
            "142/142 - 0s - loss: 1.5457e-04\n",
            "Epoch 80/100\n",
            "142/142 - 0s - loss: 1.4903e-04\n",
            "Epoch 81/100\n",
            "142/142 - 0s - loss: 1.5447e-04\n",
            "Epoch 82/100\n",
            "142/142 - 0s - loss: 1.4940e-04\n",
            "Epoch 83/100\n",
            "142/142 - 0s - loss: 1.4864e-04\n",
            "Epoch 84/100\n",
            "142/142 - 0s - loss: 1.5881e-04\n",
            "Epoch 85/100\n",
            "142/142 - 0s - loss: 1.5047e-04\n",
            "Epoch 86/100\n",
            "142/142 - 0s - loss: 1.4681e-04\n",
            "Epoch 87/100\n",
            "142/142 - 0s - loss: 1.5153e-04\n",
            "Epoch 88/100\n",
            "142/142 - 0s - loss: 1.5327e-04\n",
            "Epoch 89/100\n",
            "142/142 - 0s - loss: 1.4420e-04\n",
            "Epoch 90/100\n",
            "142/142 - 0s - loss: 1.5211e-04\n",
            "Epoch 91/100\n",
            "142/142 - 0s - loss: 1.4469e-04\n",
            "Epoch 92/100\n",
            "142/142 - 0s - loss: 1.4263e-04\n",
            "Epoch 93/100\n",
            "142/142 - 0s - loss: 1.4539e-04\n",
            "Epoch 94/100\n",
            "142/142 - 0s - loss: 1.5189e-04\n",
            "Epoch 95/100\n",
            "142/142 - 0s - loss: 1.4283e-04\n",
            "Epoch 96/100\n",
            "142/142 - 0s - loss: 1.4523e-04\n",
            "Epoch 97/100\n",
            "142/142 - 0s - loss: 1.4763e-04\n",
            "Epoch 98/100\n",
            "142/142 - 0s - loss: 1.4916e-04\n",
            "Epoch 99/100\n",
            "142/142 - 0s - loss: 1.4456e-04\n",
            "Epoch 100/100\n",
            "142/142 - 0s - loss: 1.4707e-04\n",
            "Elapsed time is 39.661138 seconds.\n",
            "Epoch 1/100\n",
            "162/162 - 2s - loss: 0.0170\n",
            "Epoch 2/100\n",
            "162/162 - 0s - loss: 6.6439e-04\n",
            "Epoch 3/100\n",
            "162/162 - 0s - loss: 3.7531e-04\n",
            "Epoch 4/100\n",
            "162/162 - 0s - loss: 3.4899e-04\n",
            "Epoch 5/100\n",
            "162/162 - 0s - loss: 3.2724e-04\n",
            "Epoch 6/100\n",
            "162/162 - 0s - loss: 3.1052e-04\n",
            "Epoch 7/100\n",
            "162/162 - 0s - loss: 3.0539e-04\n",
            "Epoch 8/100\n",
            "162/162 - 0s - loss: 2.9297e-04\n",
            "Epoch 9/100\n",
            "162/162 - 0s - loss: 2.8905e-04\n",
            "Epoch 10/100\n",
            "162/162 - 0s - loss: 2.8720e-04\n",
            "Epoch 11/100\n",
            "162/162 - 0s - loss: 2.8888e-04\n",
            "Epoch 12/100\n",
            "162/162 - 0s - loss: 2.9122e-04\n",
            "Epoch 13/100\n",
            "162/162 - 0s - loss: 2.7847e-04\n",
            "Epoch 14/100\n",
            "162/162 - 0s - loss: 2.7900e-04\n",
            "Epoch 15/100\n",
            "162/162 - 0s - loss: 2.8116e-04\n",
            "Epoch 16/100\n",
            "162/162 - 0s - loss: 2.7776e-04\n",
            "Epoch 17/100\n",
            "162/162 - 0s - loss: 2.7726e-04\n",
            "Epoch 18/100\n",
            "162/162 - 0s - loss: 2.6814e-04\n",
            "Epoch 19/100\n",
            "162/162 - 0s - loss: 2.6707e-04\n",
            "Epoch 20/100\n",
            "162/162 - 0s - loss: 2.6504e-04\n",
            "Epoch 21/100\n",
            "162/162 - 0s - loss: 2.6289e-04\n",
            "Epoch 22/100\n",
            "162/162 - 0s - loss: 2.6249e-04\n",
            "Epoch 23/100\n",
            "162/162 - 0s - loss: 2.5179e-04\n",
            "Epoch 24/100\n",
            "162/162 - 0s - loss: 2.4856e-04\n",
            "Epoch 25/100\n",
            "162/162 - 0s - loss: 2.5743e-04\n",
            "Epoch 26/100\n",
            "162/162 - 0s - loss: 2.5605e-04\n",
            "Epoch 27/100\n",
            "162/162 - 0s - loss: 2.4380e-04\n",
            "Epoch 28/100\n",
            "162/162 - 0s - loss: 2.3958e-04\n",
            "Epoch 29/100\n",
            "162/162 - 0s - loss: 2.3374e-04\n",
            "Epoch 30/100\n",
            "162/162 - 0s - loss: 2.3731e-04\n",
            "Epoch 31/100\n",
            "162/162 - 0s - loss: 2.3643e-04\n",
            "Epoch 32/100\n",
            "162/162 - 0s - loss: 2.3246e-04\n",
            "Epoch 33/100\n",
            "162/162 - 0s - loss: 2.2097e-04\n",
            "Epoch 34/100\n",
            "162/162 - 0s - loss: 2.1735e-04\n",
            "Epoch 35/100\n",
            "162/162 - 0s - loss: 2.1124e-04\n",
            "Epoch 36/100\n",
            "162/162 - 0s - loss: 2.1811e-04\n",
            "Epoch 37/100\n",
            "162/162 - 0s - loss: 2.0933e-04\n",
            "Epoch 38/100\n",
            "162/162 - 0s - loss: 2.0284e-04\n",
            "Epoch 39/100\n",
            "162/162 - 0s - loss: 2.0288e-04\n",
            "Epoch 40/100\n",
            "162/162 - 0s - loss: 2.0547e-04\n",
            "Epoch 41/100\n",
            "162/162 - 0s - loss: 2.0045e-04\n",
            "Epoch 42/100\n",
            "162/162 - 0s - loss: 2.0046e-04\n",
            "Epoch 43/100\n",
            "162/162 - 0s - loss: 1.8443e-04\n",
            "Epoch 44/100\n",
            "162/162 - 0s - loss: 1.9029e-04\n",
            "Epoch 45/100\n",
            "162/162 - 0s - loss: 1.8174e-04\n",
            "Epoch 46/100\n",
            "162/162 - 0s - loss: 1.8079e-04\n",
            "Epoch 47/100\n",
            "162/162 - 0s - loss: 1.7518e-04\n",
            "Epoch 48/100\n",
            "162/162 - 0s - loss: 1.7158e-04\n",
            "Epoch 49/100\n",
            "162/162 - 0s - loss: 1.7037e-04\n",
            "Epoch 50/100\n",
            "162/162 - 0s - loss: 1.6536e-04\n",
            "Epoch 51/100\n",
            "162/162 - 0s - loss: 1.6180e-04\n",
            "Epoch 52/100\n",
            "162/162 - 0s - loss: 1.6695e-04\n",
            "Epoch 53/100\n",
            "162/162 - 0s - loss: 1.5638e-04\n",
            "Epoch 54/100\n",
            "162/162 - 0s - loss: 1.5348e-04\n",
            "Epoch 55/100\n",
            "162/162 - 0s - loss: 1.5370e-04\n",
            "Epoch 56/100\n",
            "162/162 - 0s - loss: 1.4730e-04\n",
            "Epoch 57/100\n",
            "162/162 - 0s - loss: 1.5322e-04\n",
            "Epoch 58/100\n",
            "162/162 - 0s - loss: 1.4433e-04\n",
            "Epoch 59/100\n",
            "162/162 - 0s - loss: 1.4223e-04\n",
            "Epoch 60/100\n",
            "162/162 - 0s - loss: 1.5165e-04\n",
            "Epoch 61/100\n",
            "162/162 - 0s - loss: 1.4589e-04\n",
            "Epoch 62/100\n",
            "162/162 - 0s - loss: 1.4690e-04\n",
            "Epoch 63/100\n",
            "162/162 - 0s - loss: 1.4433e-04\n",
            "Epoch 64/100\n",
            "162/162 - 0s - loss: 1.4265e-04\n",
            "Epoch 65/100\n",
            "162/162 - 0s - loss: 1.4074e-04\n",
            "Epoch 66/100\n",
            "162/162 - 0s - loss: 1.4005e-04\n",
            "Epoch 67/100\n",
            "162/162 - 0s - loss: 1.4813e-04\n",
            "Epoch 68/100\n",
            "162/162 - 0s - loss: 1.4531e-04\n",
            "Epoch 69/100\n",
            "162/162 - 0s - loss: 1.3605e-04\n",
            "Epoch 70/100\n",
            "162/162 - 0s - loss: 1.3679e-04\n",
            "Epoch 71/100\n",
            "162/162 - 0s - loss: 1.3844e-04\n",
            "Epoch 72/100\n",
            "162/162 - 0s - loss: 1.4207e-04\n",
            "Epoch 73/100\n",
            "162/162 - 0s - loss: 1.3333e-04\n",
            "Epoch 74/100\n",
            "162/162 - 0s - loss: 1.4053e-04\n",
            "Epoch 75/100\n",
            "162/162 - 0s - loss: 1.4433e-04\n",
            "Epoch 76/100\n",
            "162/162 - 0s - loss: 1.3376e-04\n",
            "Epoch 77/100\n",
            "162/162 - 0s - loss: 1.3935e-04\n",
            "Epoch 78/100\n",
            "162/162 - 0s - loss: 1.3316e-04\n",
            "Epoch 79/100\n",
            "162/162 - 0s - loss: 1.3506e-04\n",
            "Epoch 80/100\n",
            "162/162 - 0s - loss: 1.3984e-04\n",
            "Epoch 81/100\n",
            "162/162 - 0s - loss: 1.3473e-04\n",
            "Epoch 82/100\n",
            "162/162 - 0s - loss: 1.3611e-04\n",
            "Epoch 83/100\n",
            "162/162 - 0s - loss: 1.4253e-04\n",
            "Epoch 84/100\n",
            "162/162 - 0s - loss: 1.3071e-04\n",
            "Epoch 85/100\n",
            "162/162 - 0s - loss: 1.3731e-04\n",
            "Epoch 86/100\n",
            "162/162 - 0s - loss: 1.3607e-04\n",
            "Epoch 87/100\n",
            "162/162 - 0s - loss: 1.3118e-04\n",
            "Epoch 88/100\n",
            "162/162 - 0s - loss: 1.3705e-04\n",
            "Epoch 89/100\n",
            "162/162 - 0s - loss: 1.3563e-04\n",
            "Epoch 90/100\n",
            "162/162 - 0s - loss: 1.4056e-04\n",
            "Epoch 91/100\n",
            "162/162 - 0s - loss: 1.3186e-04\n",
            "Epoch 92/100\n",
            "162/162 - 0s - loss: 1.3526e-04\n",
            "Epoch 93/100\n",
            "162/162 - 0s - loss: 1.3841e-04\n",
            "Epoch 94/100\n",
            "162/162 - 0s - loss: 1.3373e-04\n",
            "Epoch 95/100\n",
            "162/162 - 0s - loss: 1.3337e-04\n",
            "Epoch 96/100\n",
            "162/162 - 0s - loss: 1.3078e-04\n",
            "Epoch 97/100\n",
            "162/162 - 0s - loss: 1.3433e-04\n",
            "Epoch 98/100\n",
            "162/162 - 0s - loss: 1.3411e-04\n",
            "Epoch 99/100\n",
            "162/162 - 0s - loss: 1.3380e-04\n",
            "Epoch 100/100\n",
            "162/162 - 0s - loss: 1.3076e-04\n",
            "Elapsed time is 45.238444 seconds.\n",
            "Epoch 1/100\n",
            "182/182 - 2s - loss: 0.0209\n",
            "Epoch 2/100\n",
            "182/182 - 0s - loss: 7.7379e-04\n",
            "Epoch 3/100\n",
            "182/182 - 0s - loss: 4.4942e-04\n",
            "Epoch 4/100\n",
            "182/182 - 0s - loss: 3.9628e-04\n",
            "Epoch 5/100\n",
            "182/182 - 0s - loss: 3.6314e-04\n",
            "Epoch 6/100\n",
            "182/182 - 0s - loss: 3.3534e-04\n",
            "Epoch 7/100\n",
            "182/182 - 0s - loss: 3.1533e-04\n",
            "Epoch 8/100\n",
            "182/182 - 0s - loss: 3.1030e-04\n",
            "Epoch 9/100\n",
            "182/182 - 0s - loss: 3.0157e-04\n",
            "Epoch 10/100\n",
            "182/182 - 0s - loss: 2.9632e-04\n",
            "Epoch 11/100\n",
            "182/182 - 0s - loss: 2.8962e-04\n",
            "Epoch 12/100\n",
            "182/182 - 0s - loss: 2.9861e-04\n",
            "Epoch 13/100\n",
            "182/182 - 0s - loss: 2.8508e-04\n",
            "Epoch 14/100\n",
            "182/182 - 0s - loss: 2.8287e-04\n",
            "Epoch 15/100\n",
            "182/182 - 0s - loss: 2.7935e-04\n",
            "Epoch 16/100\n",
            "182/182 - 0s - loss: 2.7805e-04\n",
            "Epoch 17/100\n",
            "182/182 - 0s - loss: 2.7690e-04\n",
            "Epoch 18/100\n",
            "182/182 - 0s - loss: 2.7602e-04\n",
            "Epoch 19/100\n",
            "182/182 - 0s - loss: 2.6868e-04\n",
            "Epoch 20/100\n",
            "182/182 - 0s - loss: 2.6178e-04\n",
            "Epoch 21/100\n",
            "182/182 - 0s - loss: 2.5976e-04\n",
            "Epoch 22/100\n",
            "182/182 - 0s - loss: 2.5859e-04\n",
            "Epoch 23/100\n",
            "182/182 - 0s - loss: 2.5015e-04\n",
            "Epoch 24/100\n",
            "182/182 - 0s - loss: 2.6327e-04\n",
            "Epoch 25/100\n",
            "182/182 - 0s - loss: 2.4461e-04\n",
            "Epoch 26/100\n",
            "182/182 - 0s - loss: 2.3934e-04\n",
            "Epoch 27/100\n",
            "182/182 - 0s - loss: 2.4457e-04\n",
            "Epoch 28/100\n",
            "182/182 - 0s - loss: 2.3955e-04\n",
            "Epoch 29/100\n",
            "182/182 - 0s - loss: 2.4236e-04\n",
            "Epoch 30/100\n",
            "182/182 - 0s - loss: 2.3564e-04\n",
            "Epoch 31/100\n",
            "182/182 - 0s - loss: 2.2191e-04\n",
            "Epoch 32/100\n",
            "182/182 - 0s - loss: 2.1897e-04\n",
            "Epoch 33/100\n",
            "182/182 - 0s - loss: 2.1853e-04\n",
            "Epoch 34/100\n",
            "182/182 - 0s - loss: 2.1623e-04\n",
            "Epoch 35/100\n",
            "182/182 - 0s - loss: 2.0462e-04\n",
            "Epoch 36/100\n",
            "182/182 - 0s - loss: 2.1118e-04\n",
            "Epoch 37/100\n",
            "182/182 - 0s - loss: 2.0540e-04\n",
            "Epoch 38/100\n",
            "182/182 - 0s - loss: 2.0355e-04\n",
            "Epoch 39/100\n",
            "182/182 - 0s - loss: 1.9307e-04\n",
            "Epoch 40/100\n",
            "182/182 - 0s - loss: 1.9182e-04\n",
            "Epoch 41/100\n",
            "182/182 - 0s - loss: 1.8503e-04\n",
            "Epoch 42/100\n",
            "182/182 - 0s - loss: 1.9378e-04\n",
            "Epoch 43/100\n",
            "182/182 - 0s - loss: 1.8588e-04\n",
            "Epoch 44/100\n",
            "182/182 - 0s - loss: 1.8330e-04\n",
            "Epoch 45/100\n",
            "182/182 - 0s - loss: 1.7804e-04\n",
            "Epoch 46/100\n",
            "182/182 - 0s - loss: 1.7078e-04\n",
            "Epoch 47/100\n",
            "182/182 - 0s - loss: 1.6519e-04\n",
            "Epoch 48/100\n",
            "182/182 - 0s - loss: 1.6471e-04\n",
            "Epoch 49/100\n",
            "182/182 - 0s - loss: 1.5714e-04\n",
            "Epoch 50/100\n",
            "182/182 - 0s - loss: 1.5890e-04\n",
            "Epoch 51/100\n",
            "182/182 - 0s - loss: 1.5689e-04\n",
            "Epoch 52/100\n",
            "182/182 - 0s - loss: 1.5085e-04\n",
            "Epoch 53/100\n",
            "182/182 - 0s - loss: 1.4909e-04\n",
            "Epoch 54/100\n",
            "182/182 - 0s - loss: 1.4319e-04\n",
            "Epoch 55/100\n",
            "182/182 - 0s - loss: 1.3960e-04\n",
            "Epoch 56/100\n",
            "182/182 - 0s - loss: 1.4200e-04\n",
            "Epoch 57/100\n",
            "182/182 - 0s - loss: 1.4069e-04\n",
            "Epoch 58/100\n",
            "182/182 - 0s - loss: 1.4687e-04\n",
            "Epoch 59/100\n",
            "182/182 - 0s - loss: 1.3742e-04\n",
            "Epoch 60/100\n",
            "182/182 - 0s - loss: 1.3592e-04\n",
            "Epoch 61/100\n",
            "182/182 - 0s - loss: 1.3815e-04\n",
            "Epoch 62/100\n",
            "182/182 - 0s - loss: 1.3768e-04\n",
            "Epoch 63/100\n",
            "182/182 - 0s - loss: 1.3779e-04\n",
            "Epoch 64/100\n",
            "182/182 - 0s - loss: 1.2905e-04\n",
            "Epoch 65/100\n",
            "182/182 - 0s - loss: 1.3171e-04\n",
            "Epoch 66/100\n",
            "182/182 - 0s - loss: 1.3445e-04\n",
            "Epoch 67/100\n",
            "182/182 - 0s - loss: 1.2791e-04\n",
            "Epoch 68/100\n",
            "182/182 - 0s - loss: 1.4024e-04\n",
            "Epoch 69/100\n",
            "182/182 - 0s - loss: 1.3213e-04\n",
            "Epoch 70/100\n",
            "182/182 - 0s - loss: 1.4153e-04\n",
            "Epoch 71/100\n",
            "182/182 - 0s - loss: 1.3494e-04\n",
            "Epoch 72/100\n",
            "182/182 - 0s - loss: 1.3578e-04\n",
            "Epoch 73/100\n",
            "182/182 - 0s - loss: 1.3106e-04\n",
            "Epoch 74/100\n",
            "182/182 - 0s - loss: 1.3228e-04\n",
            "Epoch 75/100\n",
            "182/182 - 0s - loss: 1.3022e-04\n",
            "Epoch 76/100\n",
            "182/182 - 0s - loss: 1.2619e-04\n",
            "Epoch 77/100\n",
            "182/182 - 0s - loss: 1.3088e-04\n",
            "Epoch 78/100\n",
            "182/182 - 0s - loss: 1.2683e-04\n",
            "Epoch 79/100\n",
            "182/182 - 0s - loss: 1.3093e-04\n",
            "Epoch 80/100\n",
            "182/182 - 0s - loss: 1.2916e-04\n",
            "Epoch 81/100\n",
            "182/182 - 0s - loss: 1.2899e-04\n",
            "Epoch 82/100\n",
            "182/182 - 0s - loss: 1.2893e-04\n",
            "Epoch 83/100\n",
            "182/182 - 0s - loss: 1.3116e-04\n",
            "Epoch 84/100\n",
            "182/182 - 0s - loss: 1.2904e-04\n",
            "Epoch 85/100\n",
            "182/182 - 0s - loss: 1.2654e-04\n",
            "Epoch 86/100\n",
            "182/182 - 0s - loss: 1.2788e-04\n",
            "Epoch 87/100\n",
            "182/182 - 0s - loss: 1.2994e-04\n",
            "Epoch 88/100\n",
            "182/182 - 0s - loss: 1.2714e-04\n",
            "Epoch 89/100\n",
            "182/182 - 0s - loss: 1.2435e-04\n",
            "Epoch 90/100\n",
            "182/182 - 0s - loss: 1.2733e-04\n",
            "Epoch 91/100\n",
            "182/182 - 0s - loss: 1.3071e-04\n",
            "Epoch 92/100\n",
            "182/182 - 0s - loss: 1.2771e-04\n",
            "Epoch 93/100\n",
            "182/182 - 0s - loss: 1.3083e-04\n",
            "Epoch 94/100\n",
            "182/182 - 0s - loss: 1.2593e-04\n",
            "Epoch 95/100\n",
            "182/182 - 0s - loss: 1.2665e-04\n",
            "Epoch 96/100\n",
            "182/182 - 0s - loss: 1.2758e-04\n",
            "Epoch 97/100\n",
            "182/182 - 0s - loss: 1.2711e-04\n",
            "Epoch 98/100\n",
            "182/182 - 0s - loss: 1.2656e-04\n",
            "Epoch 99/100\n",
            "182/182 - 0s - loss: 1.2946e-04\n",
            "Epoch 100/100\n",
            "182/182 - 0s - loss: 1.3147e-04\n",
            "Elapsed time is 34.314352 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hs5cQMdEv8E",
        "outputId": "ae6a0ae2-23af-40f5-ba7c-f341f36c0cab"
      },
      "source": [
        "#ARIMA\n",
        "a7_model, a7_rmse, a7_mape, a7_inv_yhat, a7_inv_y, a7_running_time = Model_ARIMA (a_train_data7, a_test_data7)\n",
        "a8_model, a8_rmse, a8_mape, a8_inv_yhat, a8_inv_y, a8_running_time = Model_ARIMA (a_train_data8, a_test_data8)\n",
        "a9_model, a9_rmse, a9_mape, a9_inv_yhat, a9_inv_y, a9_running_time = Model_ARIMA (a_train_data9, a_test_data9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(0, 1215)\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "1000\n",
            "1001\n",
            "1002\n",
            "1003\n",
            "1004\n",
            "1005\n",
            "1006\n",
            "1007\n",
            "1008\n",
            "1009\n",
            "1010\n",
            "1011\n",
            "1012\n",
            "1013\n",
            "1014\n",
            "1015\n",
            "1016\n",
            "1017\n",
            "1018\n",
            "1019\n",
            "1020\n",
            "1021\n",
            "1022\n",
            "1023\n",
            "1024\n",
            "1025\n",
            "1026\n",
            "1027\n",
            "1028\n",
            "1029\n",
            "1030\n",
            "1031\n",
            "1032\n",
            "1033\n",
            "1034\n",
            "1035\n",
            "1036\n",
            "1037\n",
            "1038\n",
            "1039\n",
            "1040\n",
            "1041\n",
            "1042\n",
            "1043\n",
            "1044\n",
            "1045\n",
            "1046\n",
            "1047\n",
            "1048\n",
            "1049\n",
            "1050\n",
            "1051\n",
            "1052\n",
            "1053\n",
            "1054\n",
            "1055\n",
            "1056\n",
            "1057\n",
            "1058\n",
            "1059\n",
            "1060\n",
            "1061\n",
            "1062\n",
            "1063\n",
            "1064\n",
            "1065\n",
            "1066\n",
            "1067\n",
            "1068\n",
            "1069\n",
            "1070\n",
            "1071\n",
            "1072\n",
            "1073\n",
            "1074\n",
            "1075\n",
            "1076\n",
            "1077\n",
            "1078\n",
            "1079\n",
            "1080\n",
            "1081\n",
            "1082\n",
            "1083\n",
            "1084\n",
            "1085\n",
            "1086\n",
            "1087\n",
            "1088\n",
            "1089\n",
            "1090\n",
            "1091\n",
            "1092\n",
            "1093\n",
            "1094\n",
            "1095\n",
            "1096\n",
            "1097\n",
            "1098\n",
            "1099\n",
            "1100\n",
            "1101\n",
            "1102\n",
            "1103\n",
            "1104\n",
            "1105\n",
            "1106\n",
            "1107\n",
            "1108\n",
            "1109\n",
            "1110\n",
            "1111\n",
            "1112\n",
            "1113\n",
            "1114\n",
            "1115\n",
            "1116\n",
            "1117\n",
            "1118\n",
            "1119\n",
            "1120\n",
            "1121\n",
            "1122\n",
            "1123\n",
            "1124\n",
            "1125\n",
            "1126\n",
            "1127\n",
            "1128\n",
            "1129\n",
            "1130\n",
            "1131\n",
            "1132\n",
            "1133\n",
            "1134\n",
            "1135\n",
            "1136\n",
            "1137\n",
            "1138\n",
            "1139\n",
            "1140\n",
            "1141\n",
            "1142\n",
            "1143\n",
            "1144\n",
            "1145\n",
            "1146\n",
            "1147\n",
            "1148\n",
            "1149\n",
            "1150\n",
            "1151\n",
            "1152\n",
            "1153\n",
            "1154\n",
            "1155\n",
            "1156\n",
            "1157\n",
            "1158\n",
            "1159\n",
            "1160\n",
            "1161\n",
            "1162\n",
            "1163\n",
            "1164\n",
            "1165\n",
            "1166\n",
            "1167\n",
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n",
            "1188\n",
            "1189\n",
            "1190\n",
            "1191\n",
            "1192\n",
            "1193\n",
            "1194\n",
            "1195\n",
            "1196\n",
            "1197\n",
            "1198\n",
            "1199\n",
            "1200\n",
            "1201\n",
            "1202\n",
            "1203\n",
            "1204\n",
            "1205\n",
            "1206\n",
            "1207\n",
            "1208\n",
            "1209\n",
            "1210\n",
            "1211\n",
            "1212\n",
            "1213\n",
            "1214\n",
            "                             ARIMA Model Results                              \n",
            "==============================================================================\n",
            "Dep. Variable:                    D.y   No. Observations:                 4047\n",
            "Model:                 ARIMA(4, 1, 0)   Log Likelihood              -18277.875\n",
            "Method:                       css-mle   S.D. of innovations             22.142\n",
            "Date:                Thu, 11 Mar 2021   AIC                          36567.750\n",
            "Time:                        15:52:19   BIC                          36605.584\n",
            "Sample:                             1   HQIC                         36581.153\n",
            "                                                                              \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.1321      0.386      0.342      0.732      -0.624       0.889\n",
            "ar.L1.D.y      0.1394      0.016      8.874      0.000       0.109       0.170\n",
            "ar.L2.D.y      0.0056      0.016      0.352      0.725      -0.025       0.037\n",
            "ar.L3.D.y     -0.0111      0.016     -0.698      0.485      -0.042       0.020\n",
            "ar.L4.D.y     -0.0357      0.016     -2.276      0.023      -0.067      -0.005\n",
            "                                    Roots                                    \n",
            "=============================================================================\n",
            "                  Real          Imaginary           Modulus         Frequency\n",
            "-----------------------------------------------------------------------------\n",
            "AR.1            1.5727           -1.4284j            2.1245           -0.1174\n",
            "AR.2            1.5727           +1.4284j            2.1245            0.1174\n",
            "AR.3           -1.7275           -1.7925j            2.4894           -0.3721\n",
            "AR.4           -1.7275           +1.7925j            2.4894            0.3721\n",
            "-----------------------------------------------------------------------------\n",
            "Elapsed time is 235.043981 seconds.\n",
            "range(0, 810)\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "                             ARIMA Model Results                              \n",
            "==============================================================================\n",
            "Dep. Variable:                    D.y   No. Observations:                 4047\n",
            "Model:                 ARIMA(4, 1, 0)   Log Likelihood              -18277.875\n",
            "Method:                       css-mle   S.D. of innovations             22.142\n",
            "Date:                Thu, 11 Mar 2021   AIC                          36567.750\n",
            "Time:                        15:54:59   BIC                          36605.584\n",
            "Sample:                             1   HQIC                         36581.153\n",
            "                                                                              \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.1321      0.386      0.342      0.732      -0.624       0.889\n",
            "ar.L1.D.y      0.1394      0.016      8.874      0.000       0.109       0.170\n",
            "ar.L2.D.y      0.0056      0.016      0.352      0.725      -0.025       0.037\n",
            "ar.L3.D.y     -0.0111      0.016     -0.698      0.485      -0.042       0.020\n",
            "ar.L4.D.y     -0.0357      0.016     -2.276      0.023      -0.067      -0.005\n",
            "                                    Roots                                    \n",
            "=============================================================================\n",
            "                  Real          Imaginary           Modulus         Frequency\n",
            "-----------------------------------------------------------------------------\n",
            "AR.1            1.5727           -1.4284j            2.1245           -0.1174\n",
            "AR.2            1.5727           +1.4284j            2.1245            0.1174\n",
            "AR.3           -1.7275           -1.7925j            2.4894           -0.3721\n",
            "AR.4           -1.7275           +1.7925j            2.4894            0.3721\n",
            "-----------------------------------------------------------------------------\n",
            "Elapsed time is 159.971117 seconds.\n",
            "range(0, 405)\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "                             ARIMA Model Results                              \n",
            "==============================================================================\n",
            "Dep. Variable:                    D.y   No. Observations:                 4047\n",
            "Model:                 ARIMA(4, 1, 0)   Log Likelihood              -18277.875\n",
            "Method:                       css-mle   S.D. of innovations             22.142\n",
            "Date:                Thu, 11 Mar 2021   AIC                          36567.750\n",
            "Time:                        15:56:22   BIC                          36605.584\n",
            "Sample:                             1   HQIC                         36581.153\n",
            "                                                                              \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.1321      0.386      0.342      0.732      -0.624       0.889\n",
            "ar.L1.D.y      0.1394      0.016      8.874      0.000       0.109       0.170\n",
            "ar.L2.D.y      0.0056      0.016      0.352      0.725      -0.025       0.037\n",
            "ar.L3.D.y     -0.0111      0.016     -0.698      0.485      -0.042       0.020\n",
            "ar.L4.D.y     -0.0357      0.016     -2.276      0.023      -0.067      -0.005\n",
            "                                    Roots                                    \n",
            "=============================================================================\n",
            "                  Real          Imaginary           Modulus         Frequency\n",
            "-----------------------------------------------------------------------------\n",
            "AR.1            1.5727           -1.4284j            2.1245           -0.1174\n",
            "AR.2            1.5727           +1.4284j            2.1245            0.1174\n",
            "AR.3           -1.7275           -1.7925j            2.4894           -0.3721\n",
            "AR.4           -1.7275           +1.7925j            2.4894            0.3721\n",
            "-----------------------------------------------------------------------------\n",
            "Elapsed time is 82.314040 seconds.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFKqpc3FIcL0"
      },
      "source": [
        "### 6.1.3 Evaluation models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "asBCkQyhMxZi",
        "outputId": "c371d23d-da9f-4eff-ae86-11352443bc83"
      },
      "source": [
        "df_evaluation = pd.DataFrame(columns=['Dataset', 'Split Ratio', 'Fill method', 'Prediction', 'RMSE', 'MAPE', 'Running time'])\n",
        " \n",
        "df_evaluation = df_evaluation.append({'Dataset': 'Dataset 1st', 'Split Ratio': '70/30', 'Fill method': 'pchip', 'Prediction': 'Bayes Ridge' , \n",
        "                                      'RMSE': b7_rmse,'MAPE': b7_mape, 'Running time': running_time7}, ignore_index=True)\n",
        "df_evaluation = df_evaluation.append({'Dataset': 'Dataset 1st', 'Split Ratio': '80/20', 'Fill method': 'pchip', 'Prediction': 'Bayes Ridge' , \n",
        "                                      'RMSE': b8_rmse,'MAPE': b8_mape, 'Running time': running_time8}, ignore_index=True)\n",
        "df_evaluation = df_evaluation.append({'Dataset': 'Dataset 1st', 'Split Ratio': '90/10', 'Fill method': 'pchip', 'Prediction': 'Bayes Ridge' , \n",
        "                                      'RMSE': b9_rmse,'MAPE': b9_mape, 'Running time': running_time9}, ignore_index=True)\n",
        " \n",
        "df_evaluation = df_evaluation.append({'Dataset': 'Dataset 1st', 'Split Ratio': '70/30', 'Fill method': 'pchip', 'Prediction': 'LSTM' , \n",
        "                                      'RMSE': lstm7_rmse,'MAPE': lstm7_mape, 'Running time': lstm_running_time7}, ignore_index=True)\n",
        "df_evaluation = df_evaluation.append({'Dataset': 'Dataset 1st', 'Split Ratio': '80/20', 'Fill method': 'pchip', 'Prediction': 'LSTM' , \n",
        "                                      'RMSE': lstm8_rmse,'MAPE': lstm8_mape, 'Running time': lstm_running_time8}, ignore_index=True)\n",
        "df_evaluation = df_evaluation.append({'Dataset': 'Dataset 1st', 'Split Ratio': '90/10', 'Fill method': 'pchip', 'Prediction': 'LSTM' , \n",
        "                                      'RMSE': lstm9_rmse,'MAPE': lstm9_mape, 'Running time': lstm_running_time9}, ignore_index=True)\n",
        " \n",
        " \n",
        "df_evaluation = df_evaluation.append({'Dataset': 'Dataset 1st', 'Split Ratio': '70/30', 'Fill method': 'pchip', 'Prediction': 'ARIMA' , \n",
        "                                      'RMSE': a7_rmse,'MAPE': a7_mape, 'Running time': a7_running_time}, ignore_index=True)\n",
        "df_evaluation = df_evaluation.append({'Dataset': 'Dataset 1st', 'Split Ratio': '80/20', 'Fill method': 'pchip', 'Prediction': 'ARIMA' , \n",
        "                                      'RMSE': a8_rmse,'MAPE': a8_mape, 'Running time': a8_running_time}, ignore_index=True)\n",
        "df_evaluation = df_evaluation.append({'Dataset': 'Dataset 1st', 'Split Ratio': '90/10', 'Fill method': 'pchip', 'Prediction': 'ARIMA' , \n",
        "                                      'RMSE': a9_rmse,'MAPE': a9_mape, 'Running time': a9_running_time}, ignore_index=True)\n",
        " \n",
        "df_evaluation.sort_values(by=['Dataset', 'Split Ratio', 'RMSE', 'MAPE'], inplace=True, ascending=[True, True, True, True])\n",
        " \n",
        "cols = ['Fill method', 'Split Ratio', 'Prediction', 'RMSE', 'MAPE', 'Running time']\n",
        " \n",
        "print(df_evaluation[cols])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Fill method Split Ratio   Prediction       RMSE       MAPE  Running time\n",
            "0       pchip       70/30  Bayes Ridge  24.623078   1.084206      0.035241\n",
            "6       pchip       70/30        ARIMA  24.663887  14.221685    235.044034\n",
            "3       pchip       70/30         LSTM  25.200141   1.150771     39.661231\n",
            "4       pchip       80/20         LSTM  27.922620   1.090634     45.238572\n",
            "1       pchip       80/20  Bayes Ridge  28.087481   1.067426      0.003627\n",
            "7       pchip       80/20        ARIMA  28.109467  12.591679    159.971276\n",
            "5       pchip       90/10         LSTM  36.556462   1.201204     34.314475\n",
            "2       pchip       90/10  Bayes Ridge  36.682361   1.206034      0.002787\n",
            "8       pchip       90/10        ARIMA  36.718093  12.454391     82.314205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpk0plfHTfGK"
      },
      "source": [
        "### 6.2 Use cubic method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI-RNOjcTfGL"
      },
      "source": [
        "### 6.2.1 Split training set, test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qngP1s1TfGM"
      },
      "source": [
        "fill_df_f2 = fill_missing_values(df, fill_method='cubic',fill_order=5)\n",
        "#drop non\n",
        "dataset_f2 = drop_non_predict_columns (fill_df)\n",
        "#split dataset into training and test set\n",
        "train_X7_f2, train_y7_f2, test_X7_f2, test_y7_f2, scaler7_f2 = split_train_test (dataset_f2, traing_ratio=.7, sliding_size=4)\n",
        "train_X8_f2, train_y8_f2, test_X8_f2, test_y8_f2, scaler8_f2 = split_train_test (dataset_f2, traing_ratio=.8, sliding_size=4)\n",
        "train_X9_f2, train_y9_f2, test_X9_f2, test_y9_f2, scaler9_f2 = split_train_test (dataset_f2, traing_ratio=.9, sliding_size=4)\n",
        "\n",
        "#training for arima\n",
        "a_train_data7_f2, a_test_data7_f2 = dataset_f2[0:int(len(dataset_f2)*0.7)], dataset_f2[int(len(dataset_f2)*0.7):]\n",
        "a_train_data8_f2, a_test_data8_f2 = dataset_f2[0:int(len(dataset_f2)*0.8)], dataset_f2[int(len(dataset_f2)*0.8):]\n",
        "a_train_data9_f2, a_test_data9_f2 = dataset_f2[0:int(len(dataset_f2)*0.9)], dataset_f2[int(len(dataset_f2)*0.9):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk9EiZBWTfGP"
      },
      "source": [
        "### 6.2.2 Run models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFnpPY7NTfGQ"
      },
      "source": [
        "#BAYES RIDGE\n",
        "b7_model_f2, b7_rmse_f2, b7_mape_f2, b7_inv_yhat_f2, b7_inv_y_f2, running_time7_f2 = Model_BayesianRidge (train_X7_f2,train_y7_f2,test_X7_f2, test_y7_f2, scaler7_f2)\n",
        "b8_model_f2, b8_rmse_f2, b8_mape_f2, b8_inv_yhat_f2, b8_inv_y_f2, running_time8_f2 = Model_BayesianRidge (train_X8_f2,train_y8_f2,test_X8_f2, test_y8_f2, scaler8_f2)\n",
        "b9_model_f2, b9_rmse_f2, b9_mape_f2, b9_inv_yhat_f2, b9_inv_y_f2, running_time9_f2 = Model_BayesianRidge (train_X9_f2,train_y9_f2,test_X9_f2, test_y9_f2, scaler9_f2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VbQk-dgTfGS"
      },
      "source": [
        "#tLSTM\n",
        "lstm7_model_f2, lstm7_rmse_f2, lstm7_mape_f2, lstm7_inv_yhat_f2, lstm7_inv_y_f2, lstm_running_time7_f2 = Model_SingleLSTM (train_X7_f2,train_y7_f2,test_X7_f2, test_y7_f2, scaler7_f2)\n",
        "lstm8_model_f2, lstm8_rmse_f2, lstm8_mape_f2, lstm8_inv_yhat_f2, lstm8_inv_y_f2, lstm_running_time8_f2 = Model_SingleLSTM (train_X8_f2,train_y8_f2,test_X8_f2, test_y8_f2, scaler8_f2)\n",
        "lstm9_model_f2, lstm9_rmse_f2, lstm9_mape_f2, lstm9_inv_yhat_f2, lstm9_inv_y_f2, lstm_running_time9_f2 = Model_SingleLSTM (train_X9_f2,train_y9_f2,test_X9_f2, test_y9_f2, scaler9_f2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvRW4VHCTfGU"
      },
      "source": [
        "#ARIMA\n",
        "a7_model_f2, a7_rmse_f2, a7_mape_f2, a7_inv_yhat_f2, a7_inv_y_f2, a7_running_time_f2 = Model_ARIMA (a_train_data7_f2, a_test_data7_f2)\n",
        "a8_model_f2, a8_rmse_f2, a8_mape_f2, a8_inv_yhat_f2, a8_inv_y_f2, a8_running_time_f2 = Model_ARIMA (a_train_data8_f2, a_test_data8_f2)\n",
        "a9_model_f2, a9_rmse_f2, a9_mape_f2, a9_inv_yhat_f2, a9_inv_y_f2, a9_running_time_f2 = Model_ARIMA (a_train_data9_f2, a_test_data9_f2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk_7zcvyTfGX"
      },
      "source": [
        "### 6.2.3 Evaluation models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lvMr_qnTfGY"
      },
      "source": [
        "df_evaluation_f2 = pd.DataFrame(columns=['Dataset', 'Split Ratio', 'Fill method', 'Prediction', 'RMSE', 'MAPE', 'Running time'])\n",
        "\n",
        "df_evaluation_f2 = df_evaluation_f2.append({'Dataset': 'Dataset 1st', 'Split Ratio': '70/30', 'Fill method': 'cubic', 'Prediction': 'Bayes Ridge' , \n",
        "                                      'RMSE': b7_rmse_f2,'MAPE': b7_mape_f2, 'Running time': running_time7_f2}, ignore_index=True)\n",
        "df_evaluation_f2 = df_evaluation_f2.append({'Dataset': 'Dataset 1st', 'Split Ratio': '80/20', 'Fill method': 'cubic', 'Prediction': 'Bayes Ridge' , \n",
        "                                      'RMSE': b8_rmse_f2,'MAPE': b8_mape_f2, 'Running time': running_time8_f2}, ignore_index=True)\n",
        "df_evaluation_f2 = df_evaluation_f2.append({'Dataset': 'Dataset 1st', 'Split Ratio': '90/10', 'Fill method': 'cubic', 'Prediction': 'Bayes Ridge' , \n",
        "                                      'RMSE': b9_rmse_f2,'MAPE': b9_mape_f2, 'Running time': running_time9_f2}, ignore_index=True)\n",
        "\n",
        "df_evaluation_f2 = df_evaluation_f2.append({'Dataset': 'Dataset 1st', 'Split Ratio': '70/30', 'Fill method': 'cubic', 'Prediction': 'LSTM' , \n",
        "                                      'RMSE': lstm7_rmse_f2,'MAPE': lstm7_mape_f2, 'Running time': lstm_running_time7_f2}, ignore_index=True)\n",
        "df_evaluation_f2 = df_evaluation_f2.append({'Dataset': 'Dataset 1st', 'Split Ratio': '80/20', 'Fill method': 'cubic', 'Prediction': 'LSTM' , \n",
        "                                      'RMSE': lstm8_rmse_f2,'MAPE': lstm8_mape_f2, 'Running time': lstm_running_time8_f2}, ignore_index=True)\n",
        "df_evaluation_f2 = df_evaluation_f2.append({'Dataset': 'Dataset 1st', 'Split Ratio': '90/10', 'Fill method': 'cubic', 'Prediction': 'LSTM' , \n",
        "                                      'RMSE': lstm9_rmse_f2,'MAPE': lstm9_mape_f2, 'Running time': lstm_running_time9_f2}, ignore_index=True)\n",
        "\n",
        "\n",
        "df_evaluation_f2 = df_evaluation_f2.append({'Dataset': 'Dataset 1st', 'Split Ratio': '70/30', 'Fill method': 'cubic', 'Prediction': 'ARIMA' , \n",
        "                                      'RMSE': a7_rmse_f2,'MAPE': a7_mape_f2, 'Running time': a7_running_time_f2}, ignore_index=True)\n",
        "df_evaluation_f2 = df_evaluation_f2.append({'Dataset': 'Dataset 1st', 'Split Ratio': '80/20', 'Fill method': 'cubic', 'Prediction': 'ARIMA' , \n",
        "                                      'RMSE': a8_rmse_f2,'MAPE': a8_mape_f2, 'Running time': a8_running_time_f2}, ignore_index=True)\n",
        "df_evaluation_f2 = df_evaluation_f2.append({'Dataset': 'Dataset 1st', 'Split Ratio': '90/10', 'Fill method': 'cubic', 'Prediction': 'ARIMA' , \n",
        "                                      'RMSE': a9_rmse_f2,'MAPE': a9_mape_f2, 'Running time': a9_running_time_f2}, ignore_index=True)\n",
        "\n",
        "df_evaluation_f2.sort_values(by=['Dataset', 'Split Ratio', 'RMSE', 'MAPE'], inplace=True, ascending=[True, True, True, True])\n",
        "\n",
        "cols = ['Fill method', 'Split Ratio', 'Prediction', 'RMSE', 'MAPE', 'Running time']\n",
        "\n",
        "print(df_evaluation_f2[cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCK_SsL7f-8k"
      },
      "source": [
        "## 6.3 Combination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo77cFCbgB8i"
      },
      "source": [
        "df_evaluation_f1f2 = pd.concat([df_evaluation, df_evaluation_f2], ignore_index=True)\n",
        "\n",
        "df_evaluation_f1f2.sort_values(by=['Dataset', 'Split Ratio', 'RMSE', 'MAPE'], inplace=True, ascending=[True, True, True, True])\n",
        "\n",
        "cols = ['Fill method', 'Split Ratio', 'Prediction', 'RMSE', 'MAPE', 'Running time']\n",
        "\n",
        "print(df_evaluation_f1f2[cols].head(50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3mT8iLZTfGa"
      },
      "source": [
        "### 6.3.1 Fill: pchip, Split: 70/30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2Ftd4eqF05V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tddCzKIRTfGa"
      },
      "source": [
        "# plot \n",
        "pyplot.figure(figsize=(20,6))\n",
        "\n",
        "pyplot.plot([x for x in range(1, b7_inv_y.shape[0]+1)], b7_inv_y, linestyle='solid',linewidth=3, color='black', label='Actual')\n",
        "pyplot.plot([x for x in range(1, lstm7_inv_yhat.shape[0]+1)], lstm7_inv_yhat, linestyle='--', color='purple', label='Prediction - LSTM')\n",
        "pyplot.plot([x for x in range(1, b7_inv_yhat.shape[0]+1)], b7_inv_yhat, linestyle='--', color='red', label='Prediction - Bayes Ridge')\n",
        "pyplot.plot(a7_inv_yhat, linestyle='--', color='cyan', label='Prediction - ARIMA')\n",
        "\n",
        "pyplot.legend(loc=1, prop={'size': 12})\n",
        "pyplot.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6aXeORaTfGc"
      },
      "source": [
        "**Zoom in**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn7ylxe1TfGf"
      },
      "source": [
        "# plot \n",
        "pyplot.figure(figsize=(20,6))\n",
        "\n",
        "pyplot.plot([x for x in range(1, b7_inv_y.shape[0]+1)], b7_inv_y, linestyle='solid',linewidth=3, color='black', label='Actual')\n",
        "pyplot.plot([x for x in range(1, lstm7_inv_yhat.shape[0]+1)], lstm7_inv_yhat, linestyle='--', color='purple', label='Prediction - LSTM')\n",
        "pyplot.plot([x for x in range(1, b7_inv_yhat.shape[0]+1)], b7_inv_yhat, linestyle='-', color='red', label='Prediction - Bayes Ridge')\n",
        "pyplot.plot(a7_inv_yhat, linestyle='--', color='cyan', label='Prediction - ARIMA')\n",
        "\n",
        "pyplot.legend(loc=1, prop={'size': 12})\n",
        "pyplot.xlim([340,360])\n",
        "pyplot.ylim([900,1430])\n",
        "\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVGKyuecwTbA"
      },
      "source": [
        "# plot \n",
        "pyplot.figure(figsize=(20,6))\n",
        "\n",
        "pyplot.plot([x for x in range(1, b8_inv_y.shape[0]+1)], b8_inv_y, linestyle='solid',linewidth=3, color='black', label='Actual')\n",
        "pyplot.plot([x for x in range(1, lstm8_inv_yhat.shape[0]+1)], lstm8_inv_yhat, linestyle='--', color='purple', label='Prediction - LSTM')\n",
        "pyplot.plot([x for x in range(1, b8_inv_yhat.shape[0]+1)], b8_inv_yhat, linestyle='--', color='red', label='Prediction - Bayes Ridge')\n",
        "pyplot.plot(a8_inv_yhat, linestyle='--', color='cyan', label='Prediction - ARIMA')\n",
        "\n",
        "pyplot.legend(loc=1, prop={'size': 12})\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNlU_N8twn85"
      },
      "source": [
        "# plot \n",
        "pyplot.figure(figsize=(20,6))\n",
        "\n",
        "pyplot.plot([x for x in range(1, b8_inv_y.shape[0]+1)], b8_inv_y, linestyle='solid',linewidth=3, color='black', label='Actual')\n",
        "pyplot.plot([x for x in range(1, lstm8_inv_yhat.shape[0]+1)], lstm8_inv_yhat, linestyle='--', color='purple', label='Prediction - LSTM')\n",
        "pyplot.plot([x for x in range(1, b8_inv_yhat.shape[0]+1)], b8_inv_yhat, linestyle='--', color='red', label='Prediction - Bayes Ridge')\n",
        "pyplot.plot(a7_inv_yhat, linestyle='--', color='cyan', label='Prediction - ARIMA')\n",
        "\n",
        "pyplot.legend(loc=1, prop={'size': 12})\n",
        "pyplot.xlim([340,360])\n",
        "pyplot.ylim([900,1430])\n",
        "\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOHaANsBZD06"
      },
      "source": [
        "### 6.3.1 Fill: pchip, Split: 80/20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOcE7E1qZWJY"
      },
      "source": [
        "# plot \n",
        "pyplot.figure(figsize=(20,6))\n",
        "\n",
        "pyplot.plot([x for x in range(1, b8_inv_y.shape[0]+1)], b8_inv_y, linestyle='solid',linewidth=3, color='black', label='Actual')\n",
        "pyplot.plot([x for x in range(1, lstm8_inv_yhat.shape[0]+1)], lstm8_inv_yhat, linestyle='--', color='purple', label='Prediction - LSTM')\n",
        "pyplot.plot([x for x in range(1, b8_inv_yhat.shape[0]+1)], b8_inv_yhat, linestyle='-', color='red', label='Prediction - Bayes Ridge')\n",
        "pyplot.plot(a8_inv_yhat, linestyle='--', color='cyan', label='Prediction - ARIMA')\n",
        "\n",
        "pyplot.legend(loc=1, prop={'size': 12})\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B93KGQC0Z3Xu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7LopcOhZ4Mx"
      },
      "source": [
        "# plot \n",
        "pyplot.figure(figsize=(20,6))\n",
        "\n",
        "pyplot.plot([x for x in range(1, b9_inv_y.shape[0]+1)], b9_inv_y, linestyle='solid',linewidth=3, color='black', label='Actual')\n",
        "pyplot.plot([x for x in range(1, lstm9_inv_yhat.shape[0]+1)], lstm9_inv_yhat, linestyle='--', color='purple', label='Prediction - LSTM')\n",
        "pyplot.plot([x for x in range(1, b9_inv_yhat.shape[0]+1)], b9_inv_yhat, linestyle='-', color='red', label='Prediction - Bayes Ridge')\n",
        "pyplot.plot(a9_inv_yhat, linestyle='--', color='cyan', label='Prediction - ARIMA')\n",
        "\n",
        "pyplot.legend(loc=1, prop={'size': 12})\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lO-plSPxu6z"
      },
      "source": [
        "# plot \n",
        "pyplot.figure(figsize=(20,6))\n",
        "\n",
        "pyplot.plot([x for x in range(1, b9_inv_y.shape[0]+1)], b9_inv_y, linestyle='solid',linewidth=3, color='black', label='Actual')\n",
        "pyplot.plot([x for x in range(1, lstm9_inv_yhat.shape[0]+1)], lstm9_inv_yhat, linestyle='--', color='purple', label='Prediction - LSTM')\n",
        "pyplot.plot([x for x in range(1, b9_inv_yhat.shape[0]+1)], b9_inv_yhat, linestyle='-', color='red', label='Prediction - Bayes Ridge')\n",
        "pyplot.plot(a9_inv_yhat, linestyle='--', color='cyan', label='Prediction - ARIMA')\n",
        "\n",
        "pyplot.legend(loc=1, prop={'size': 12})\n",
        "pyplot.xlim([340,360])\n",
        "pyplot.ylim([900,1430])\n",
        "\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}